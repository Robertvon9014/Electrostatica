{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"M\u00e9todos Num\u00e9ricos para la Ecuaci\u00f3n de Laplace","text":"<p>En este proyeto se implementa y compara distintos m\u00e9todos num\u00e9ricos para resolver la ecuaci\u00f3n diferencial de Laplace en dos dimensiones, modelando  un capacitor ideal en una placa cuadrada 10 cm x 10 cm</p> <p>Incluimos las siguientes implementaciones: - M\u00e9todo de relajaci\u00f3n de Jacobi (Python) - M\u00e9todo de sobre-relajaci\u00f3n de Jacobi (Python) - M\u00e9todo de Gauss-Seidel (Python) - M\u00e9todo de Gauss-Seide (C++)</p> <p>El objetivo es compara la eficiencia y convergencia de los m\u00e9todos para la resoluci\u00f3n del potencial electroest\u00e1tito de una malla discreta, con condiciones de frontera internas simulando las placas del capacitos.</p> <p>Para m\u00e1s informaci\u00f3n consultar los apartados de explicaci\u00f3n y tutoriales.</p>"},{"location":"#contenidos","title":"Contenidos","text":"<ul> <li>Explicaci\u00f3n</li> <li>Tutoriales</li> </ul>"},{"location":"explanation/","title":"Explicaci\u00f3n de los M\u00e9todos Num\u00e9ricos","text":""},{"location":"explanation/#problema-fisico","title":"Problema f\u00edsico","text":"<p>Se resuelve la ecuaci\u00f3n de Laplace bidimensional para el potencial el\u00e9ctrico \\(\\phi(x,y)\\):</p> \\[ \\frac{\\partial^2 \\phi}{\\partial x^2} + \\frac{\\partial^2 \\phi}{\\partial y^2} = 0 \\] <p>Esta ecuaci\u00f3n nos permite describir el comportamiento de un potencial el\u00e9ctrico sobre una regi\u00f3n donde no existen cargas libres (es decir, en el  vac\u00edo o en materiales diel\u00e9ctricos).</p> <p>El dominio de este problema se encuentra  en una placa cuadrada de 10 cm \u00d7 10 cm, con dos barras internas que simulan las placas de un capacitor: - Una barra se localiza cerca del borde izquierdo y se mantiene con potencial constante positivo \\(V_p\\). - Otra barra se encuentra cerca del borde derecho con potencial negativo \\(V_n\\).</p> <p>La longitud de ambas barras es de 6 cm, y estan separadas a la misma distancia que su longitud, lo cual nos permite visualizar una configuraci\u00f3n sim\u00e9trica con respecto al eje horizontal.</p> <p>Condiciones del problema:   - En la condiciones del problemas donde no se especifique el potencial se asume que la condici\u00f3n de frontera tiene un valor inicial de cero, o      bien el potencial se actualiza iterativamente hasta converger.</p>"},{"location":"explanation/#metodos-implementados","title":"M\u00e9todos implementados","text":""},{"location":"explanation/#1-metodo-de-relajacion-de-jacobi","title":"1. M\u00e9todo de relajaci\u00f3n de Jacobi","text":"<p>Este m\u00e9todo itera actualizando el potencial en cada punto de la malla usando el promedio de sus vecinos en la iteraci\u00f3n anterior, manteniendo fijas las condiciones de frontera.</p> \\[ \\phi'(x, y) = \\frac{1}{4}\\left[\\phi(x+a, y) + \\phi(x-a, y) + \\phi(x, y+a) + \\phi(x, y-a)\\right], \\] <p>La idea principal de este m\u00e9todo es que se actualiza el valor del potencial el\u00e9ctrico \\(\\phi(x,y)\\) en cada punto de la grilla como el promedio de los valores de sus vecinos adyacentes(arriba, abajo, izquierda, derecha) que se agarran de los datos iterativos anteriores, mientras mantenemos fijas las condiciones de frontera.</p> <p>Esto se repite hasta que hayamos alcanzado una diferencia m\u00e1xima entre dos iteraciones consecutivas, es lo que llamamos \"el delta\", y que este sea menor que una tolerancia escogida. Lo que nos indicar\u00e1 que hemos alcanzado la convergencia.</p> <ul> <li>Es sencillo pero convergencia lenta.</li> <li>Requiere dos matrices para mantener valores antiguos y nuevos.</li> </ul>"},{"location":"explanation/#2-metodo-de-sobre-relajacion-de-jacobi-jacobi-modificado","title":"2. M\u00e9todo de sobre-relajaci\u00f3n de Jacobi (Jacobi modificado)","text":"<p>Se aplica un factor de sobre-relajaci\u00f3n \\(\\omega\\) para acelerar la convergencia, mezclando el valor nuevo calculado con el anterior:</p> \\[ \\phi'(x, y) = (1+\\omega)\\left[\\frac{\\phi(x+a, y) + \\phi(x-a, y) + \\phi(x, y+a) + \\phi(x, y-a)}4\\right] - \\omega \\phi (x,y). \\] <ul> <li>Acelera la convergencia respecto al Jacobi est\u00e1ndar.</li> <li>Requiere ajuste del par\u00e1metro \\(\\omega\\) para optimizar rendimiento.</li> </ul> <p>Limitaciones:  No siempre el m\u00e9todo de Sobre-relajaci\u00f3n de jacobi funcionar\u00e1 yaa que este m\u00e9todo es muy inestable para grillas cuadradas, esto sucede debido a que  el m\u00e9todo no actualiza los valores al instante como lo hace Gauss-Seidel, es por ello que al intentar la sobre-relajaci\u00f3n los valores del error se  amplifican, esto debido a las condiciones de frontera internas, como lo son las barras con un voltaje de \\(\\pm 1\\), como estan internamente esto  permite la generaci\u00f3n de una regi\u00f3n central en la cual los errores circulan libremente sin ser frenados por los bordes r\u00edgidos. Debido a que este  m\u00e9todo se vuelv num\u00e9ricamente inestable incluso para valores \\(\\omega &lt; 1\\), esto nos demuestra que la estabilidad del m\u00e9todo no solo va a depender  del factor de relajaci\u00f3n \\(\\omega\\), sino tambi\u00e9n de la geometr\u00eda del problema y las condiciones de frontera.</p> <p>Una forma de poder utilizar el m\u00e9todo de sobre-relajaci\u00f3n de jacobi, para una placa cuadrada con barras internar con voltaje, es utilizar el m\u00e9todo  de sobre-relajaci\u00f3n sucesiva (SOR) lo que nos permite esto es hacer iteraciones paralelas sin necesidad de usar valores ya actualizados.</p> \\[ \\phi'(x, y) = (1 - \\omega) \\cdot \\phi(x, y) + \\frac{\\omega}{4} \\cdot \\left( \\phi(x+1, y) + \\phi(x-1, y) + \\phi(x, y+1) + \\phi(x, y-1) \\right) \\]"},{"location":"explanation/#3-metodo-de-gauss-seidel","title":"3. M\u00e9todo de Gauss-Seidel","text":"<p>En este m\u00e9todo, la actualizaci\u00f3n del potencial en cada punto usa los valores m\u00e1s recientes disponibles (actualizados durante la misma iteraci\u00f3n),  mejorando la velocidad de convergencia frente a Jacobi. Esto facilita a la informaci\u00f3n propagarse m\u00e1s r\u00e1pidamente a trav\u00e9s de la grilla.</p> \\[ \\phi(x, y) \\leftarrow \\frac{\\phi(x+a, y) + \\phi(x-a, y) + \\phi(x, y+a) + \\phi(x, y-a)}{4}. \\] <ul> <li>Solo se necesita una matriz.</li> <li>Mejor convergencia en menos iteraciones.</li> <li>Los valores recien calculados se utilizan en el mismo ciclo.</li> </ul> <p>aunque este m\u00e9todo es m\u00e1s r\u00e1pido que Jacobi, la forma(orden) de actualizar los puntos puede influir en la estabilidad y el patr\u00f3n de error.</p>"},{"location":"explanation/#4-metodo-de-gauss-seidel-en-c","title":"4. M\u00e9todo de Gauss-Seidel en C++","text":"<p>Implementaci\u00f3n equivalente al m\u00e9todo de Gauss-Seidel en Python, pero usando C++ con <code>std::vector</code> y <code>std::tuple</code>.</p> <ul> <li>Permite una posible extensi\u00f3n para paralelizaci\u00f3n.</li> <li>Mejora en eficiencia y manejo de memoria para casos grandes.</li> </ul>"},{"location":"explanation/#condiciones-de-frontera-y-configuracion-de-la-grilla","title":"Condiciones de frontera y configuraci\u00f3n de la grilla","text":"<ul> <li>La placa se discretiza en una malla de \\((M+1) \\times (M+1)\\) puntos.</li> <li>Dos barras verticales se colocan a 2 cm de cada borde lateral, con longitudes de 6 cm, y potenciales fijos \\(V_p\\) y \\(V_n\\).</li> <li>El resto de bordes y posiciones iniciales son 0.</li> </ul>"},{"location":"explanation/#convergencia-y-criterio-de-parada","title":"Convergencia y criterio de parada","text":"<p>La iteraci\u00f3n se detiene cuando la diferencia m\u00e1xima absoluta entre iteraciones consecutivas es menor que una tolerancia dada.</p>"},{"location":"explanation/#comparacion-y-resultados","title":"Comparaci\u00f3n y resultados","text":"<ul> <li>El m\u00e9todo de Gauss-Seidel converge m\u00e1s r\u00e1pido que Jacobi.</li> <li>La sobre-relajaci\u00f3n mejora a\u00fan m\u00e1s la velocidad si se escoge un \\(\\omega\\) adecuado (por ejemplo, 0.9). Adem\u00e1s de ello la forma geom\u00e9trica y las condiciones de frontera son las adecuadas.</li> <li>La implementaci\u00f3n en C++ es m\u00e1s eficiente y es base para paralelizaci\u00f3n futura.</li> </ul>"},{"location":"explanation/#grafica-de-escalabilidad","title":"Gr\u00e1fica de escalabilidad","text":"<p>En esta secci\u00f3n incluiremos una gr\u00e1fica de escalabilidad tomando en cuenta 2 hilos(threads) y para 3 tama\u00f1os de M distintos(M = 500, 1000, 1500). </p>"},{"location":"explanation/#analisis","title":"An\u00e1lisis","text":"M Hilos Speedup real Speedup ideal 500 1 1.00 1 500 2 1.68 2 1000 1 1.00 1 1000 2 1.55 2 1500 1 1.00 1 1500 2 1.54 2 <ul> <li>Speedup ideal es la aceleraci\u00f3n m\u00e1xima te\u00f3rica, que aumenta linealmente con el n\u00famero de hilos (por ejemplo, con 2 hilos, el speedup ideal es 2).</li> <li>Speedup real muestra los valores obtenido al correr el c\u00f3digo en la computadora.</li> </ul> <p>Observaciones 1. Aceleraci\u00f3n sublineal:      En todos los casos, el speedup real con 2 hilos est\u00e1 por debajo del ideal (1.68, 1.55 y 1.54 en vez de 2). Esto es normal y esperado debido a:</p> <pre><code>  - Sobrecarga de gesti\u00f3n de hilos.\n  - Costos de sincronizaci\u00f3n y comunicaci\u00f3n entre threads.\n  - Acceso a memoria compartida y posibles contenciones.\n</code></pre> <ol> <li> <p>Mejor escalabilidad con problema peque\u00f1o (M=500):     El speedup para \\(\ud835\udc40 = 500\\) con 2 hilos (1.68) es mayor que para \\(\ud835\udc40 = 1000\\) y \\(\ud835\udc40 = 1500\\) (alrededor de 1.55). Esto puede ser por:</p> <ul> <li>El trabajo extra por manejar datos mayores y la sobrecarga paralela que no escala igual.</li> <li>O bien, diferencias en la carga de trabajo por iteraci\u00f3n (aunque usualmente problemas m\u00e1s grandes escalan mejor, puede depender de      implementaci\u00f3n).</li> </ul> </li> <li> <p>Escalabilidad limitada a 2 hilos:       Solo se tiene datos para 1 y 2 hilos. Con solo dos puntos es dif\u00edcil trazar conclusiones s\u00f3lidas. Idealmente, pruebas con m\u00e1s hilos ayudar\u00edan        a ver tendencias.</p> </li> </ol>"},{"location":"reference/","title":"Referencias","text":""},{"location":"reference/#metodo-de-relajacion-de-jacobi","title":"M\u00e9todo de relajaci\u00f3n de Jacobi","text":""},{"location":"reference/#src.jaccobi.jacobi_relaxation","title":"<code>jacobi_relaxation(L, M, V_p, V_n, tolerance)</code>","text":"<p>Resuelve el potencial el\u00e9ctrico en una placa cuadrada usando el m\u00e9todo de relajaci\u00f3n de Jacobi.</p> <p>Se modela la regi\u00f3n cuadrada de tama\u00f1o <code>L x L</code>dividida en <code>M x M</code> puntos. Se tienen dos barras verticales que se colocan como condiciones de frontera internas: Una posee un potencial <code>V_p</code> y otra con <code>V_n</code>. La funci\u00f3n itera hasta que el cambio m\u00e1ximo entre iteraciones sea menor que la <code>tolerance</code>.</p> <p>Parameters:</p> Name Type Description Default <code>L</code> <code>int</code> <p>Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).</p> required <code>M</code> <code>int</code> <p>N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).</p> required <code>V_p</code> <code>float</code> <p>Voltaje aplicado en la barra positiva.</p> required <code>V_n</code> <code>float</code> <p>Voltaje aplicado en la barra negativa.</p> required <code>tolerance</code> <code>float</code> <p>Tolerancia para el criterio de convergencia.</p> required <p>Returns:</p> Name Type Description <code>phi</code> <code>ndarray</code> <p>Matriz de 2 dimensiones con potenciales verticales dados por dos barras.</p> <code>its</code> <code>int</code> <p>N\u00famero de iteraciones realizadas.</p> <code>delta</code> <code>float</code> <p>Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; phi, its, error = jacobi_relaxation(10, 100, 1.0, -1.0, 1e-5)\n&gt;&gt;&gt; print(f\"Iteraciones: {its}, Error final: {error:.2e}\")\nIteraciones: 1794, Error final: 9.99e-06\n</code></pre> Source code in <code>src/jaccobi.py</code> <pre><code>def jacobi_relaxation(L, M, V_p, V_n, tolerance):\n    \"\"\"\n    Resuelve el potencial el\u00e9ctrico en una placa cuadrada usando el m\u00e9todo de relajaci\u00f3n de Jacobi.\n\n    Se modela la regi\u00f3n cuadrada de tama\u00f1o `L x L`dividida en `M x M` puntos.\n    Se tienen dos barras verticales que se colocan como condiciones de frontera internas:\n    Una posee un potencial `V_p` y otra con `V_n`. La funci\u00f3n itera hasta que el cambio\n    m\u00e1ximo entre iteraciones sea menor que la `tolerance`.\n\n    Args:\n        L (int): Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).\n        M (int): N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).\n        V_p (float): Voltaje aplicado en la barra positiva.\n        V_n (float): Voltaje aplicado en la barra negativa.\n        tolerance (float): Tolerancia para el criterio de convergencia.\n\n    Returns:\n        phi (ndarray): Matriz de 2 dimensiones con potenciales verticales dados por dos barras.\n        its (int): N\u00famero de iteraciones realizadas.\n        delta (float): Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.\n\n    Examples:\n        &gt;&gt;&gt; phi, its, error = jacobi_relaxation(10, 100, 1.0, -1.0, 1e-5)\n        &gt;&gt;&gt; print(f\"Iteraciones: {its}, Error final: {error:.2e}\")\n        Iteraciones: 1794, Error final: 9.99e-06\n    \"\"\"\n    # Primero creamos los arreglos 2-dimensionales de la grilla\n    # Vamos a necesitar dos seg\u00fan la regla de Jacobi\n    # Note que usamos M+1, debido a que debemos contener la condici\u00f3n de frontera\n    # phi contiene inicialmente los valores iniciales. Vamos a utilizar ceros.\n    phi = np.zeros((M + 1, M + 1), dtype=float)\n    # Ahora tenemos que colocar la condici\u00f3n inicial.\n    # Recuerde accesos de listas en np.ndarray\n\n    # Validamos que M sea mayor a 10\n    if M &lt;= 10:\n        raise ValueError(\"El tama\u00f1o de la grilla (M) debe ser mayor a 10\")\n\n    # --- Calculamos la reposici\u00f3n dependiendo el tama\u00f1o de M\n    fil_start = int(M * 0.2) # 2 cm desde arriba\n    bar_len = int(M * 0.6)   # 6 cm longitud de la barra\n    fil_end = fil_start + bar_len\n\n    col_plus = int(M * 0.2)  # Voltaje positivo a 2 cm del borde izquierdo\n    col_neg = col_plus + bar_len # Voltaje Negativo a 2 cm del borde derecho\n\n    # Ahora tenemos que colocar la condici\u00f3n inicial.\n    # Recuerde accesos de listas en np.ndarray\n    phi[fil_start:fil_end, col_plus] = V_p  # Barra positiva\n    phi[fil_start:fil_end, col_neg] = V_n    # Barra negativa\n\n    # phiprime se necesita para la iteraci\u00f3n\n    phiprime = np.zeros((M + 1, M + 1), dtype=float)\n    # Iteraci\u00f3n de Jacobi\n    delta = 1.0\n    its = 0\n    while delta &gt; tolerance:\n        # Calculamos la iteraci\u00f3n\n        its += 1\n        for i in range(M + 1):\n            for j in range(M + 1):\n                # Condici\u00f3n de frontera\n                if j == col_plus and fil_start &lt;= i &lt;= fil_end or j == col_neg and fil_start &lt;= i &lt;= fil_end:\n                    phiprime[i, j] = phi[i,j]\n                elif i == 0 or i == M or j == 0 or j == M:\n                    phiprime[i, j] = phi[i, j]\n                # Iteraci\u00f3n principal\n                else:\n                # COMPLETE AQU\u00cd\n                    phiprime[i,j] = 0.25 * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1])\n        # Calculamos la diferencia m\u00e1xima con respecto a los valores anteriores\n        delta = np.max(np.abs(phi - phiprime))\n        # Ahora intercambiamos los arreglos para la nueva iteraci\u00f3n\n        # El nuevo phi es el phiprime\n        temp = phi\n        phi = phiprime\n        # El nuevo phiprime es el phi viejo\n        phiprime = temp\n\n    return phi, its, delta\n</code></pre>"},{"location":"reference/#metodo-de-sobre-relajacion-de-jacobi","title":"M\u00e9todo de Sobre-relajaci\u00f3n de Jacobi","text":""},{"location":"reference/#src.jaccobi_modified.jacobi_modified","title":"<code>jacobi_modified(L, M, V_p, V_n, omega, tolerance)</code>","text":"<p>Aplicamos el m\u00e9todo de Jacobi modificado con sobre-relajaci\u00f3n para resolver el potencial el\u00e9ctrico en una placa cuadrada con condiciones de frontera internas.</p> <p>Se modela la regi\u00f3n cuadrada de tama\u00f1o <code>L x L</code>dividida en <code>M x M</code> puntos. Se tienen dos barras verticales que se colocan como condiciones de frontera internas: Una posee un potencial <code>V_p</code> y otra con <code>V_n</code>. Se actualiza iterativamente el potencial en el resto de la grilla usando un factor de sobre-relajaci\u00f3n <code>omega</code> para acelerar la convergencia.</p> <p>Parameters:</p> Name Type Description Default <code>L</code> <code>int</code> <p>Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).</p> required <code>M</code> <code>int</code> <p>N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).</p> required <code>V_p</code> <code>float</code> <p>Voltaje aplicado en la barra positiva.</p> required <code>V_n</code> <code>float</code> <p>Voltaje aplicado en la barra negativa.</p> required <code>tolerance</code> <code>float</code> <p>Tolerancia para el criterio de convergencia.</p> required <p>Returns:</p> Name Type Description <code>phi</code> <code>ndarray</code> <p>Matriz de 2 dimensiones con potenciales verticales dados por dos barras.</p> <code>its</code> <code>int</code> <p>N\u00famero de iteraciones realizadas.</p> <code>delta</code> <code>float</code> <p>Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; phi, its, error = jacobi_modified(10, 100, 1.0, -1.0, 1e-5)\n&gt;&gt;&gt; print(f\"Iteraciones: {its}, Error final: {error:.2e}\")\nerror en la iteraci\u00f3n.\n</code></pre> Source code in <code>src/jaccobi_modified.py</code> <pre><code>def jacobi_modified(L, M, V_p, V_n, omega, tolerance):\n    \"\"\"\n    Aplicamos el m\u00e9todo de Jacobi modificado con sobre-relajaci\u00f3n para resolver\n    el potencial el\u00e9ctrico en una placa cuadrada con condiciones de frontera internas.\n\n    Se modela la regi\u00f3n cuadrada de tama\u00f1o `L x L`dividida en `M x M` puntos.\n    Se tienen dos barras verticales que se colocan como condiciones de frontera internas:\n    Una posee un potencial `V_p` y otra con `V_n`. Se actualiza iterativamente el potencial\n    en el resto de la grilla usando un factor de sobre-relajaci\u00f3n `omega` para acelerar la convergencia.\n\n    Args:\n        L (int): Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).\n        M (int): N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).\n        V_p (float): Voltaje aplicado en la barra positiva.\n        V_n (float): Voltaje aplicado en la barra negativa.\n        tolerance (float): Tolerancia para el criterio de convergencia.\n\n    Returns:\n        phi (ndarray): Matriz de 2 dimensiones con potenciales verticales dados por dos barras.\n        its (int): N\u00famero de iteraciones realizadas.\n        delta (float): Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.\n\n    Examples:\n        &gt;&gt;&gt; phi, its, error = jacobi_modified(10, 100, 1.0, -1.0, 1e-5)\n        &gt;&gt;&gt; print(f\"Iteraciones: {its}, Error final: {error:.2e}\")\n        error en la iteraci\u00f3n.\n    \"\"\"\n    # Primero creamos los arreglos 2-dimensionales de la grilla\n    # Vamos a necesitar dos seg\u00fan la regla de Jacobi\n    # Note que usamos M+1, debido a que debemos contener la condici\u00f3n de frontera\n    # phi contiene inicialmente los valores iniciales. Vamos a utilizar ceros.\n    phi = np.zeros((M + 1, M + 1), dtype=float)\n\n    # Validamos que el tama\u00f1o M sea mayor a 10\n    if M &lt;= 10:\n        raise ValueError(\"El tama\u00f1o de la grilla (M) deber ser mayor a 10\")\n\n    # --- Calculamos la reposici\u00f3n dependiendo del valor de M\n    fil_start = int(0.2 * M) # 2 cm desde arriba\n    vol_len = int(0.6 * M)   # 6 cm longitud de la barra\n    fil_end = fil_start + vol_len\n\n    col_plus = int(0.2 * M)  # voltaje positivo a 2 cm del borde izquierdo\n    col_neg = col_plus + vol_len # Voltaje negativo a 2 cm del borde derecho\n\n    # Ahora tenemos que colocar la condici\u00f3n inicial.\n    # Recuerde accesos de listas en np.ndarray\n    phi[fil_start:fil_end, col_plus] = V_p\n    phi[fil_start:fil_end, col_neg] = V_n\n    # phiprime se necesita para la iteraci\u00f3n\n    phiprime = np.zeros((M + 1, M + 1), dtype=float)\n    # Iteraci\u00f3n de Jacobi\n    delta = 1.0\n    its = 0\n    while delta &gt; tolerance:\n        # Calculamos la iteraci\u00f3n\n        its += 1\n        for i in range(M + 1):\n            for j in range(M + 1):\n                if j == col_plus and fil_start &lt;= i &lt;= fil_end or j == col_neg and fil_start &lt;= i &lt;= fil_end:\n                    phiprime[i, j] = phi[i, j]\n                # Condici\u00f3n de frontera\n                elif i == 0 or i == M or j == 0 or j == M:\n                    phiprime[i, j] = phi[i, j]\n                # Iteraci\u00f3n principal\n                else:\n                # COMPLETE AQU\u00cd\n                    phiprime[i,j] = (1 + omega) * (0.25 * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1])) - (omega * phi[i,j])\n                    #phiprime[i,j] = (1 - omega) * phi[i,j] + (omega / 4) * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1])\n        # Calculamos la diferencia m\u00e1xima con respecto a los valores anteriores\n        delta = np.max(np.abs(phi - phiprime))\n        # Ahora intercambiamos los arreglos para la nueva iteraci\u00f3n\n        # El nuevo phi es el phiprime\n        temp = phi\n        phi = phiprime\n        # El nuevo phiprime es el phi viejo\n        phiprime = temp\n    return phi, its, delta\n</code></pre>"},{"location":"reference/#metodo-de-gauss-seidel","title":"M\u00e9todo de Gauss-seidel","text":""},{"location":"reference/#src.gauss_seidel.gauss_seidel","title":"<code>gauss_seidel(L, M, V_p, V_n, tolerance)</code>","text":"<p>Resuelve el potencial el\u00e9ctrico en una placa cuadrada usando el m\u00e9todo de Gauss-seidel.</p> <p>Se modela la regi\u00f3n cuadrada de tama\u00f1o <code>L x L</code>dividida en <code>M x M</code> puntos. Se tienen dos barras verticales que se colocan como condiciones de frontera internas: Una posee un potencial <code>V_p</code> y otra con <code>V_n</code>. La funci\u00f3n itera hasta que el cambio m\u00e1ximo entre iteraciones sea menor que la <code>tolerance</code>.</p> <p>Parameters:</p> Name Type Description Default <code>L</code> <code>int</code> <p>Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).</p> required <code>M</code> <code>int</code> <p>N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).</p> required <code>V_p</code> <code>float</code> <p>Voltaje aplicado en la barra positiva.</p> required <code>V_n</code> <code>float</code> <p>Voltaje aplicado en la barra negativa.</p> required <code>tolerance</code> <code>float</code> <p>Tolerancia para el criterio de convergencia.</p> required <p>Returns:</p> Name Type Description <code>phi</code> <code>ndarray</code> <p>Matriz de 2 dimensiones con potenciales verticales dados por dos barras.</p> <code>its</code> <code>int</code> <p>N\u00famero de iteraciones realizadas.</p> <code>delta</code> <code>float</code> <p>Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; phi, its, error = jacobi_relaxation(10, 100, 1.0, -1.0, 1e-5)\n&gt;&gt;&gt; print(f\"Convergencia alcanzada en {itertions} iteraciones con error de {error:.2e}\")\nConvergencia alcanzada en 1125 iteraciones con error de 9.97e-06\n</code></pre> Source code in <code>src/gauss_seidel.py</code> <pre><code>def gauss_seidel(L, M, V_p, V_n, tolerance):\n    \"\"\"\n    Resuelve el potencial el\u00e9ctrico en una placa cuadrada usando el m\u00e9todo de Gauss-seidel.\n\n    Se modela la regi\u00f3n cuadrada de tama\u00f1o `L x L`dividida en `M x M` puntos.\n    Se tienen dos barras verticales que se colocan como condiciones de frontera internas:\n    Una posee un potencial `V_p` y otra con `V_n`. La funci\u00f3n itera hasta que el cambio\n    m\u00e1ximo entre iteraciones sea menor que la `tolerance`.\n\n    Args:\n        L (int): Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).\n        M (int): N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).\n        V_p (float): Voltaje aplicado en la barra positiva.\n        V_n (float): Voltaje aplicado en la barra negativa.\n        tolerance (float): Tolerancia para el criterio de convergencia.\n\n    Returns:\n        phi (ndarray): Matriz de 2 dimensiones con potenciales verticales dados por dos barras.\n        its (int): N\u00famero de iteraciones realizadas.\n        delta (float): Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.\n\n    Examples:\n        &gt;&gt;&gt; phi, its, error = jacobi_relaxation(10, 100, 1.0, -1.0, 1e-5)\n        &gt;&gt;&gt; print(f\"Convergencia alcanzada en {itertions} iteraciones con error de {error:.2e}\")\n        Convergencia alcanzada en 1125 iteraciones con error de 9.97e-06\n    \"\"\"\n    # Primero creamos el arreglo 2-dimensionales de la grilla\n    # Note que usamos M+1, debido a que debemos contener la condici\u00f3n de frontera\n    # phi contiene inicialmente los valores iniciales. Vamos a utilizar ceros.\n    phi = np.zeros((M + 1, M + 1), dtype=float)\n\n    # Validamos que M sea mayor que 10\n    if M &lt;= 10:\n        raise ValueError(\"El tama\u00f1o de la grila (M) debe ser mayor a 10\")\n\n    # --- Calculamos la reposici\u00f3n dependiendo del valor de M\n    fil_start = int(M * 0.2) # 2 cm desde arriba\n    vol_len = int(M * 0.6)   # 6 cm longitud de la barra\n    fil_end = fil_start + vol_len\n\n    col_plus = int(M * 0.2)  # voltaje positivo a 2 cm del borde izquierdo\n    col_neg = col_plus + vol_len # Voltaje negativo a 2 cm del borde derecho\n\n    # Ahora tenemos que colocar la condici\u00f3n inicial.\n    # Recuerde accesos de listas en np.ndarray\n    phi[fil_start:fil_end, col_plus] = V_p\n    phi[fil_start:fil_end, col_neg] = V_n\n    # Vamos a guardar una copia para evaluar el error\n    phi_copy = phi.copy()\n    # Iteraci\u00f3n de Gauss-Seidel\n    delta = 1.0\n    its = 0\n    while delta &gt; tolerance:\n        # Calculamos la iteraci\u00f3n\n        its += 1\n        for i in range(1, M):\n            for j in range(1, M):\n                # Condici\u00f3n de frontera\n                # En este caso, en la frontera los valores no se modifican\n                if fil_start &lt;= i &lt;= fil_end and (j == col_plus or j == col_neg):\n                    continue\n                # Iteraci\u00f3n principal\n                else:\n                    # COMPLETE AQU\u00cd\n                    phi[i,j] = 0.25 * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1] )\n        # Calculamos la diferencia m\u00e1xima con respecto a los valores anteriores\n        delta = np.max(np.abs(phi - phi_copy))\n        # Copiamos los valores de la nueva iteraci\u00f3n\n        phi_copy = phi.copy()\n\n    return phi, its, delta\n</code></pre>"},{"location":"tutorials/","title":"Tutorial","text":"<p>En esta parte nos centraremos en un efonque orientado al aprendizaje. Aprenderemos como instalar las bibliotecas a utilizar y como implementar el  m\u00e9todo de relajacion de Jacobi. Los m\u00e9todos de sobre-relajaci\u00f3n de Jacobi y Gauss-Seidel siguen la misma m\u00e9todolog\u00eda de implementaci\u00f3n exceptuando  los c\u00f3digos de C++ que sus bibliotecas a utilizar y compilaci\u00f3n es distinta.</p>"},{"location":"tutorials/#requisitos-previos","title":"Requisitos previos","text":"<p>Antes de comenzar necesitamos tener instalado la siguiente biblioteca en nuestro entorno de python: <pre><code>pip instal numpy\npip install matplotlib\n</code></pre></p>"},{"location":"tutorials/#paso-1-configuramos-el-entorno","title":"Paso 1: Configuramos el entorno","text":"<p>Abrimos el editor de c\u00f3digo <code>vim</code> y creamor el nuevo archivo de python. Por ejemplo, lo llamamos jacobi.py</p>"},{"location":"tutorials/#paso-2-importamos-bibliotecas","title":"Paso 2: Importamos bibliotecas","text":"<p>Comenzamos importando las bibliotecas requeridas para el c\u00f3digo de Jacobi, Sobre-relajaci\u00f3n de Jacobi, Gauss-seidel y Gauss-Seidel implementado en C++ y paralelizado con memoria compartida y distribuida.</p> <pre><code>import numpy as np               # Biblioteca para operaciones num\u00e9ricas eficientes, especialmente con arreglos y matrices\nimport matplotlib.pyplot as plt  # M\u00f3dulo principal para graficar en 2D con una interfaz similar a MATLAB\nimport matplotlib.cm as cm       # Acceso a los mapas de colores (colormaps) predefinidos de Matplotlib\n</code></pre> <p>Librer\u00edas usadas para Gauss-seidel <pre><code>#include &lt;iostream&gt;      // Biblioteca est\u00e1ndar para entrada/salida (cout, cerr, etc.)\n#include &lt;cmath&gt;         // Biblioteca matem\u00e1tica (std::abs, std::pow, std::sqrt, etc.)\n#include &lt;vector&gt;        // Contenedor din\u00e1mico tipo array (std::vector)\n#include &lt;tuple&gt;         // Permite usar std::tuple para retornar m\u00faltiples valores\n</code></pre></p> <p>Librer\u00edas usadas para Gauss-Seidel Memoria compartida <pre><code>#include &lt;iostream&gt;      // Biblioteca est\u00e1ndar para entrada/salida (cout, cerr, etc.)\n#include &lt;cmath&gt;         // Biblioteca matem\u00e1tica (std::abs, std::pow, std::sqrt, etc.)\n#include &lt;vector&gt;        // Contenedor din\u00e1mico tipo array (std::vector)\n#include &lt;tuple&gt;         // Permite usar std::tuple para retornar m\u00faltiples valores\n#include &lt;sys/time.h&gt;    // Biblioteca para manejo de tiempo con mayor precisi\u00f3n (gettimeofday)\n#include &lt;omp.h&gt;         // Biblioteca para programaci\u00f3n paralela con OpenMP\n#include &lt;iomanip&gt;       // Biblioteca para manipular formato de salida (std::setprecision, std::fixed)\n</code></pre></p>"},{"location":"tutorials/#paso-3-definimos-las-funciones-que-retornaran-los-metodos-de-jacobi-sobre-relajacion-de-jacobi-gauss-seidel-y-gauss-seidel-en-memoria-compartida-y-distribuida","title":"Paso 3: Definimos las funciones que retornar\u00e1n los m\u00e9todos de Jacobi, Sobre-relajaci\u00f3n de Jacobi, Gauss-Seidel, y Gauss-Seidel en memoria compartida y distribuida.","text":"<p>M\u00e9todo de relajaci\u00f3n de Jacobi <pre><code>def jacobi_relaxation(L, M, V_p, V_n, tolerance):\n    # Primero creamos los arreglos 2-dimensionales de la grilla\n    # Vamos a necesitar dos seg\u00fan la regla de Jacobi\n    # Note que usamos M+1, debido a que debemos contener la condici\u00f3n de frontera\n    # phi contiene inicialmente los valores iniciales. Vamos a utilizar ceros.\n    phi = np.zeros((M + 1, M + 1), dtype=float)\n\n    # --- Calculamos la reposici\u00f3n dependiendo del valor de M\n    fil_start = int((2 * M) / L) # 2 cm desde arriba\n    vol_len = int((6 * M) / L)   # 6 cm longitud de la barra\n    fil_end = fil_start + vol_len\n\n    col_plus = int((2 * M) / L)  # voltaje positivo a 2 cm del borde izquierdo\n    col_neg = col_plus + vol_len # Voltaje negativo a 2 cm del borde derecho\n\n    # Ahora tenemos que colocar la condici\u00f3n inicial.\n    # Recuerde accesos de listas en np.ndarray\n    phi[fil_start:fil_end, col_plus] = V_p\n    phi[fil_start:fil_end, col_neg] = V_n\n    # phiprime se necesita para la iteraci\u00f3n\n    phiprime = np.zeros((M + 1, M + 1), dtype=float)\n    # Iteraci\u00f3n de Jacobi\n    delta = 1.0\n    its = 0\n    while delta &gt; tolerance:\n        # Calculamos la iteraci\u00f3n\n        its += 1\n        for i in range(M + 1):\n            for j in range(M + 1):\n                if j == col_plus and fil_start &lt;= i &lt;= fil_end or j == col_neg and fil_start &lt;= i &lt;= fil_end:\n                    phiprime[i, j] = phi[i, j]\n                # Condici\u00f3n de frontera\n                elif i == 0 or i == M or j == 0 or j == M:\n                    phiprime[i, j] = phi[i, j]\n                # Iteraci\u00f3n principal\n                else:\n                # COMPLETE AQU\u00cd\n                    phiprime[i,j] = 0.25 * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1])\n        # Calculamos la diferencia m\u00e1xima con respecto a los valores anteriores\n        delta = np.max(np.abs(phi - phiprime))\n        # Ahora intercambiamos los arreglos para la nueva iteraci\u00f3n\n        # El nuevo phi es el phiprime\n        temp = phi\n        phi = phiprime\n        # El nuevo phiprime es el phi viejo\n        phiprime = temp\n    return phi, its, delta\n</code></pre></p> <p>M\u00e9todo de Sobre-relajaci\u00f3n de jacobi <pre><code>def jacobi_modified(L, M, V_p, V_n, omega, tolerance):\n    \"\"\"\n    Aplicamos el m\u00e9todo de Jacobi modificado con sobre-relajaci\u00f3n para resolver\n    el potencial el\u00e9ctrico en una placa cuadrada con condiciones de frontera internas.\n\n    Se modela la regi\u00f3n cuadrada de tama\u00f1o `L x L`dividida en `M x M` puntos.\n    Se tienen dos barras verticales que se colocan como condiciones de frontera internas:\n    Una posee un potencial `V_p` y otra con `V_n`. Se actualiza iterativamente el potencial\n    en el resto de la grilla usando un factor de sobre-relajaci\u00f3n `omega` para acelerar la convergencia.\n\n    Args:\n        L (int): Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).\n        M (int): N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).\n        V_p (float): Voltaje aplicado en la barra positiva.\n        V_n (float): Voltaje aplicado en la barra negativa.\n        tolerance (float): Tolerancia para el criterio de convergencia.\n\n    Returns:\n        phi (ndarray): Matriz de 2 dimensiones con potenciales verticales dados por dos barras.\n        its (int): N\u00famero de iteraciones realizadas.\n        delta (float): Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.\n\n    Examples:\n        &gt;&gt;&gt; phi, its, error = jacobi_modified(10, 100, 1.0, -1.0, 1e-5)\n        &gt;&gt;&gt; print(f\"Iteraciones: {its}, Error final: {error:.2e}\")\n        error en la iteraci\u00f3n.\n    \"\"\"\n    # Primero creamos los arreglos 2-dimensionales de la grilla\n    # Vamos a necesitar dos seg\u00fan la regla de Jacobi\n    # Note que usamos M+1, debido a que debemos contener la condici\u00f3n de frontera\n    # phi contiene inicialmente los valores iniciales. Vamos a utilizar ceros.\n    phi = np.zeros((M + 1, M + 1), dtype=float)\n\n    # Validamos que el tama\u00f1o M sea mayor a 10\n    if M &lt;= 10:\n        raise ValueError(\"El tama\u00f1o de la grilla (M) deber ser mayor a 10\")\n\n    # --- Calculamos la reposici\u00f3n dependiendo del valor de M\n    fil_start = int(0.2 * M) # 2 cm desde arriba\n    vol_len = int(0.6 * M)   # 6 cm longitud de la barra\n    fil_end = fil_start + vol_len\n\n    col_plus = int(0.2 * M)  # voltaje positivo a 2 cm del borde izquierdo\n    col_neg = col_plus + vol_len # Voltaje negativo a 2 cm del borde derecho\n\n    # Ahora tenemos que colocar la condici\u00f3n inicial.\n    # Recuerde accesos de listas en np.ndarray\n    phi[fil_start:fil_end, col_plus] = V_p\n    phi[fil_start:fil_end, col_neg] = V_n\n    # phiprime se necesita para la iteraci\u00f3n\n    phiprime = np.zeros((M + 1, M + 1), dtype=float)\n    # Iteraci\u00f3n de Jacobi\n    delta = 1.0\n    its = 0\n    while delta &gt; tolerance:\n        # Calculamos la iteraci\u00f3n\n        its += 1\n        for i in range(M + 1):\n            for j in range(M + 1):\n                if j == col_plus and fil_start &lt;= i &lt;= fil_end or j == col_neg and fil_start &lt;= i &lt;= fil_end:\n                    phiprime[i, j] = phi[i, j]\n                # Condici\u00f3n de frontera\n                elif i == 0 or i == M or j == 0 or j == M:\n                    phiprime[i, j] = phi[i, j]\n                # Iteraci\u00f3n principal\n                else:\n                # COMPLETE AQU\u00cd\n                    phiprime[i,j] = (1 + omega) * (0.25 * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1])) - (omega * phi[i,j])\n                    #phiprime[i,j] = (1 - omega) * phi[i,j] + (omega / 4) * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1])\n        # Calculamos la diferencia m\u00e1xima con respecto a los valores anteriores\n        delta = np.max(np.abs(phi - phiprime))\n        # Ahora intercambiamos los arreglos para la nueva iteraci\u00f3n\n        # El nuevo phi es el phiprime\n        temp = phi\n        phi = phiprime\n        # El nuevo phiprime es el phi viejo\n        phiprime = temp\n    return phi, its, delta\n</code></pre></p> <p>M\u00e9todo de Gauss-Seidel</p> <pre><code>def gauss_seidel(L, M, V_p, V_n, tolerance):\n    \"\"\"\n    Resuelve el potencial el\u00e9ctrico en una placa cuadrada usando el m\u00e9todo de Gauss-seidel.\n\n    Se modela la regi\u00f3n cuadrada de tama\u00f1o `L x L`dividida en `M x M` puntos.\n    Se tienen dos barras verticales que se colocan como condiciones de frontera internas:\n    Una posee un potencial `V_p` y otra con `V_n`. La funci\u00f3n itera hasta que el cambio\n    m\u00e1ximo entre iteraciones sea menor que la `tolerance`.\n\n    Args:\n        L (int): Tama\u00f1o f\u00edsico de la placa cuadrada (dado en cm).\n        M (int): N\u00famero de divisiones de la grilla (grilla de (M+1) x (M+1)).\n        V_p (float): Voltaje aplicado en la barra positiva.\n        V_n (float): Voltaje aplicado en la barra negativa.\n        tolerance (float): Tolerancia para el criterio de convergencia.\n\n    Returns:\n        phi (ndarray): Matriz de 2 dimensiones con potenciales verticales dados por dos barras.\n        its (int): N\u00famero de iteraciones realizadas.\n        delta (float): Error m\u00e1ximo alcanzado en la \u00faltima iteraci\u00f3n.\n\n    Examples:\n        &gt;&gt;&gt; phi, its, error = jacobi_relaxation(10, 100, 1.0, -1.0, 1e-5)\n        &gt;&gt;&gt; print(f\"Convergencia alcanzada en {itertions} iteraciones con error de {error:.2e}\")\n        Convergencia alcanzada en 1125 iteraciones con error de 9.97e-06\n    \"\"\"\n    # Primero creamos el arreglo 2-dimensionales de la grilla\n    # Note que usamos M+1, debido a que debemos contener la condici\u00f3n de frontera\n    # phi contiene inicialmente los valores iniciales. Vamos a utilizar ceros.\n    phi = np.zeros((M + 1, M + 1), dtype=float)\n\n    # Validamos que M sea mayor que 10\n    if M &lt;= 10:\n        raise ValueError(\"El tama\u00f1o de la grila (M) debe ser mayor a 10\")\n\n    # --- Calculamos la reposici\u00f3n dependiendo del valor de M\n    fil_start = int(M * 0.2) # 2 cm desde arriba\n    vol_len = int(M * 0.6)   # 6 cm longitud de la barra\n    fil_end = fil_start + vol_len\n\n    col_plus = int(M * 0.2)  # voltaje positivo a 2 cm del borde izquierdo\n    col_neg = col_plus + vol_len # Voltaje negativo a 2 cm del borde derecho\n\n    # Ahora tenemos que colocar la condici\u00f3n inicial.\n    # Recuerde accesos de listas en np.ndarray\n    phi[fil_start:fil_end, col_plus] = V_p\n    phi[fil_start:fil_end, col_neg] = V_n\n    # Vamos a guardar una copia para evaluar el error\n    phi_copy = phi.copy()\n    # Iteraci\u00f3n de Gauss-Seidel\n    delta = 1.0\n    its = 0\n    while delta &gt; tolerance:\n        # Calculamos la iteraci\u00f3n\n        its += 1\n        for i in range(1, M):\n            for j in range(1, M):\n                # Condici\u00f3n de frontera\n                # En este caso, en la frontera los valores no se modifican\n                if fil_start &lt;= i &lt;= fil_end and (j == col_plus or j == col_neg):\n                    continue\n                # Iteraci\u00f3n principal\n                else:\n                    # COMPLETE AQU\u00cd\n                    phi[i,j] = 0.25 * (phi[i + 1, j] + phi[i - 1, j] + phi[i, j + 1] + phi[i, j - 1] )\n        # Calculamos la diferencia m\u00e1xima con respecto a los valores anteriores\n        delta = np.max(np.abs(phi - phi_copy))\n        # Copiamos los valores de la nueva iteraci\u00f3n\n        phi_copy = phi.copy()\n\n    return phi, its, delta\n</code></pre> <p>M\u00e9todo de Gauss-Seidel Memoria Compartida <pre><code>double seconds(){\n  struct timeval tmp;\n  double sec;\n  gettimeofday( &amp;tmp, (struct timezone *)0 );\n  sec = tmp.tv_sec + ((double)tmp.tv_usec)/1000000.0;\n\n  return sec;\n}\n\n/**\n * @brief Resuelve el potencial el\u00e9ctrico en una placa cuadrada con m\u00e9todo Gauss-Seidel usando red-black ordering y OpenMP.\n *\n * Se impone una grilla de tama\u00f1o `M x M` sobre la placa, con dos barras verticales:\n * una con voltaje positivo `V_p` y otra con voltaje negativo `V_n`. \n * El algoritmo aplica el m\u00e9todo de Gauss-Seidel con ordenamiento red-black en paralelo.\n *\n * @param M N\u00famero de divisiones de la grilla (debe ser mayor a 10)\n * @param V_p Voltaje positivo aplicado\n * @param V_n Voltaje negativo aplicado\n * @param tolerance Tolerancia para el criterio de convergencia\n * @param num_procs Referencia donde se guardar\u00e1 el n\u00famero de procesos/hilos usados\n * @return std::tuple&lt;int, double&gt; N\u00famero de iteraciones realizadas y error final\n */\n\nstd::tuple&lt;int, double&gt; gaussseidel(int M, double V_p, double V_n, double tolerance, int &amp;num_procs){\n  // Creamos un arreglo de 2-dimensiones usando std::vector\n  using Matrix = std::vector&lt;std::vector&lt;double&gt;&gt;;\n  Matrix phi(M + 1, std::vector&lt;double&gt;(M + 1, 0.0));\n\n  // ---- Validar que M sea mayor a 10\n  if (M &lt;= 10){\n    throw std::runtime_error(\"El tama\u00f1o de la grilla (M) debe ser mayor a 10\");\n  }\n\n  // ---- Calcular la reposici\u00f3n dependiendo del valor de M\n  // ---- Posiciones expresadas en \u00edndices de grilla\n  // ---- usamos static_cast&lt;int&gt; para convertir de double a int de forma segura\n  int fil_start = static_cast&lt;int&gt;(M * 0.2);        // 2 cm desde arriba\n  int bar_len = static_cast&lt;int&gt;(M * 0.6);          // longitud de la barra 6 cm\n  int fil_end = fil_start + bar_len;\n\n  int col_plus = static_cast&lt;int&gt;(M * 0.2);         // Voltaje positivo a 2 cm del borde izquierdo\n  int col_neg = col_plus + bar_len;                 // Voltaje negativo a 2 cm del borde derecho\n\n  // Colocamos las posiciones iniciales\n  for (int i = fil_start; i &lt; fil_end; ++i){\n    phi[i][col_plus] = V_p;\n    phi[i][col_neg] = V_n;\n  }\n\n  // Guardamos una copia\n  Matrix phi_copy = phi;\n\n  // Iteraci\u00f3n de Gauss-seidel\n  double delta = 1.0;\n  int its = 0;\n  while (delta &gt; tolerance){\n    its += 1;\n    #pragma omp parallel \n    {\n      #pragma omp single\n      {\n        num_procs = omp_get_num_threads();\n      }\n      /* --- Implementar el m\u00e9todo de red-black ordering\n       * Este m\u00e9todo consiste en colorear todo el dominio \n       * de la grilla como si fuera un tablero de ajedrez:\n       * en celdas rojas y negras\n       * R N R N \n       * N R N R \n       * R N R N \n       * N R N R\n       * La clave de este m\u00e9todo es que cada paso iremos \n       * actualizando las celdas rojas primero (usando las\n       * negras) y luego las celdas negras (usando las rojas\n       * reci\u00e9n actualizadas). */\n\n      // Actualizamos las celdas rojas\n      #pragma omp for collapse(2)\n      for (int i = 1; i &lt; M; ++i){\n        for (int j = 1; j &lt; M; ++j){\n          if ((i + j) % 2 == 0){\n            if ((fil_start &lt;= i &amp;&amp; i &lt;= fil_end) &amp;&amp; (j == col_plus || j == col_neg)){\n              continue;\n            }\n            else{\n              phi[i][j] = 0.25 * (phi[i + 1][j] + phi[i - 1][j] + phi[i][j + 1] + phi[i][j - 1]);\n            }\n          }\n        }\n      }\n\n      // Actualizamos las celdas negras\n      #pragma omp for collapse(2)\n      for (int i = 1; i &lt; M; ++i){\n        for (int j = 1; j &lt; M; ++j){\n          if ((i + j) % 2 == 1){\n            if ((fil_start &lt;= i &amp;&amp; i &lt;= fil_end) &amp;&amp; (j == col_plus || j == col_neg)){\n              continue;\n            }\n            else{\n              phi[i][j] = 0.25 * (phi[i + 1][j] + phi[i - 1][j] + phi[i][j + 1] + phi[i][j -1]);\n            }\n          }\n        }\n      }\n    }\n\n    // Calculamos la diferencia m\u00e1xima con respecto a los valores anteriores\n    delta = 0.0;\n    #pragma omp parallel reduction(max:delta)\n    {\n      #pragma omp for\n      for (int i = 0; i &lt;= M; ++i){\n        for (int j = 0; j &lt;= M; ++j){\n          double diferencia = std::abs(phi[i][j] - phi_copy[i][j]);\n          if (diferencia &gt; delta){\n            delta = diferencia;\n          }\n        }\n      }\n    }\n\n    // Copiamos los valores de la nueva iteraci\u00f3n\n\n    phi_copy = phi;\n  }\n\n  //std::cout &lt;&lt; \"phi[50][25] = \" &lt;&lt; phi[50][25] &lt;&lt; std::endl;\n  return std::make_tuple(its, delta);\n}\n</code></pre> M\u00e9todo de Gauss-Seidel Memoria Distribuida <pre><code>double seconds(){\n  struct timeval tmp;\n  gettimeofday(&amp;tmp, nullptr);\n  return tmp.tv_sec + tmp.tv_usec * 1e-6;\n}\n\n// Funci\u00f3n principal paralela usando memoria distribuida\n/**\n * @brief Resuelve el potencial el\u00e9ctrico en una placa usando el m\u00e9todo de Gauss-Seidel con ordenamiento red-black y MPI.\n *\n * Se divide la grilla de tama\u00f1o `M x M` entre los procesos disponibles.\n * Cada proceso calcula una porci\u00f3n del dominio y colabora usando comunicaci\u00f3n punto a punto.\n * Se usan halos (bordes fantasma) para compartir informaci\u00f3n entre procesos vecinos.\n * \n * @param L Longitud de la placa (no se usa en el c\u00e1lculo actual)\n * @param M N\u00famero de divisiones en la grilla (resoluci\u00f3n espacial)\n * @param V_p Voltaje positivo aplicado a una barra vertical\n * @param V_n Voltaje negativo aplicado a otra barra vertical\n * @param tolerance Tolerancia para el criterio de convergencia (m\u00e1ximo delta permitido)\n * @return std::tuple&lt;int, double&gt; Par con n\u00famero de iteraciones realizadas y el error final (delta)\n */\n\n// Funci\u00f3n principal paralela usando memoria distribuida\nstd::tuple&lt;int, double&gt; gaussseidel_mpi(int L, int M, double V_p, double V_n, double tolerance){\n  using Matrix = std::vector&lt;std::vector&lt;double&gt;&gt;;\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &amp;size);\n\n  if (M &lt;= 10) throw std::runtime_error(\"M &gt; 10\");\n\n  // Determinar cu\u00e1ntas filas maneja cada proceso\n  int local_rows = M / size;\n  int rem = M % size;\n  int start = rank * (local_rows) + std::min(rank, rem) + 1;\n  local_rows += (rank &lt; rem ? 1 : 0);\n  int end = start + local_rows - 1; // inclusive\n\n  // Creamos matriz local con halos (2 filas extra)\n  int cols = M + 1;\n  Matrix phi(local_rows + 2, std::vector&lt;double&gt;(cols, 0.0));\n  Matrix phi_copy = phi;\n\n  // Calculamos posici\u00f3n de barras globales\n  // ---- usamos static_cast&lt;int&gt; para convertir de double a int de forma segura\n  int fil_start = static_cast&lt;int&gt;(M * 0.2);        // 2 cm desde arriba\n  int bar_len = static_cast&lt;int&gt;(M * 0.6);          // longitud de la barra 6 cm\n  int fil_end = fil_start + bar_len;\n\n  int col_plus = static_cast&lt;int&gt;(M * 0.2);         // Voltaje positivo a 2 cm del borde izquierdo\n  int col_neg = col_plus + bar_len;                 // Voltaje negativo a 2 cm del borde derecho\n\n  // Inicializaci\u00f3n: cada fila (global i = start..end)\n  for (int gi = start; gi &lt;= end; ++gi){\n    if (gi &gt;= fil_start &amp;&amp; gi &lt; fil_end){\n      phi[gi - start + 1][col_plus] = V_p;\n      phi[gi - start + 1][col_neg]  = V_n;\n    }\n  }\n\n  double delta = 1.0;\n  int its = 0;\n\n  while (delta &gt; tolerance){\n    its += 1;\n\n    // -- Intercambio halo superior/inferior\n    MPI_Request active_reqs[4];\n    int num_reqs = 0;\n\n    if(rank &gt; 0){\n      MPI_Irecv(&amp;phi[0][0], cols, MPI_DOUBLE, rank - 1, 0, MPI_COMM_WORLD, &amp;active_reqs[num_reqs++]);\n      MPI_Isend(&amp;phi[1][0], cols, MPI_DOUBLE, rank - 1, 1, MPI_COMM_WORLD, &amp;active_reqs[num_reqs++]);\n    }\n    if(rank &lt; (size - 1)){\n      MPI_Irecv(&amp;phi[local_rows + 1][0], cols, MPI_DOUBLE, rank + 1, 1, MPI_COMM_WORLD, &amp;active_reqs[num_reqs++]);\n      MPI_Isend(&amp;phi[local_rows][0], cols, MPI_DOUBLE, rank + 1, 0, MPI_COMM_WORLD, &amp;active_reqs[num_reqs++]);\n    }\n\n    MPI_Waitall(num_reqs, active_reqs, MPI_STATUSES_IGNORE);\n\n    // --- Actualizamos celdas rojas\n    for (int i = 1; i &lt;= local_rows; ++i){\n      for (int j = 1; j &lt; M; ++j){\n        int gi = start + i -1; // gi = global i\n        if ((gi + j) % 2 == 0){\n          if ((fil_start &lt;= gi &amp;&amp; gi &lt;= fil_end) &amp;&amp; ( j == col_plus || j == col_neg)){\n            continue;\n          }\n          else{\n            phi[i][j] = 0.25 * (phi[i + 1][j] + phi[i - 1][j] + phi[i][j  + 1] + phi[i][j - 1]);\n          }\n        }\n      }\n    }\n\n    // --- Actualizamos las celdas negras\n    for (int i = 1; i &lt;= local_rows; ++i){\n      for (int j = 1; j &lt; M; ++j){\n        int gi = start + i - 1;\n        if ((gi + j) % 2 == 1){\n          if ((fil_start &lt;= gi &amp;&amp; gi &lt;= fil_end) &amp;&amp; (j == col_plus || j == col_neg)){\n            continue;\n          }\n          else{\n            phi[i][j] = 0.25 * (phi[i + 1][j] + phi[i - 1 ][j] + phi[i][j + 1] + phi[i][j - 1]);\n          }\n        }\n      }\n    }\n    MPI_Barrier(MPI_COMM_WORLD); // Sincronizamos los colores\n\n    // --- C\u00e1lculo del delta local\n    delta = 0.0;\n    for (int i = 1; i &lt;= local_rows; ++i){\n      for (int j = 1; j &lt;= M; ++j){\n        double diferencia = std::abs(phi[i][j] - phi_copy[i][j]);\n        if (diferencia &gt; delta){\n          delta = diferencia;\n        }\n      }\n    }\n\n    // --- Reducci\u00f3n global del delta\n    MPI_Allreduce(MPI_IN_PLACE, &amp;delta, 1, MPI_DOUBLE, MPI_MAX, MPI_COMM_WORLD);\n\n    // --- Copiamos los valores de la nueva iteraci\u00f3n\n    phi_copy = phi;\n  }\n\n  // --- Imprimir el proceso que posee la fila 50\n  int gi_target = 50;\n  if (start &lt;= gi_target &amp;&amp; gi_target &lt;= end){\n    int li = gi_target - start + 1; \n    std::cout &lt;&lt; \"phi[50][25] = \" &lt;&lt; phi[li][25] &lt;&lt; std::endl;\n  }\n\n  return std::make_tuple(its, delta);\n}\n</code></pre></p>"},{"location":"tutorials/#paso-4-llamado-a-la-funcion","title":"Paso 4: Llamado a la funci\u00f3n","text":"<p>En esta parte escribimos el llamado a la funci\u00f3n para almacenar los resultados en nuevas variables y poder realizar la impresi\u00f3n en pantalla</p> <ul> <li> <p>Llamado a la funci\u00f3n del M\u00e9todo de Jacobi   <pre><code>jacobi_vals, iterations, error = jacobi_relaxation(10, 100, 1.0, -1.0, 1e-5)\nprint(f\"Convergencia alcanzada en {iterations} iteraciones con error {error:.2e}\")\n</code></pre></p> </li> <li> <p>Llamado a la funci\u00f3n del M\u00e9todo de Sobre-relajaci\u00f3n de Jacobi   <pre><code>jacobiModified_vals, iterations, error = jacobi_modified(10, 100, 1.0, -1.0, 0.9, 1e-5)\nprint(f\"Convergencia alcanzada en {iterations} iteraciones con error {error}\")\n</code></pre></p> </li> <li>Llamado a la funci\u00f3n del m\u00e9todo de Gauss-Seidel   <pre><code>gaussSeidel_vals, iterations, error = gauss_seidel(10, 100, 1.0, -1.0, 1e-5)\nprint(f\"Convergencia alcanzada en {iterations} iteraciones con error de {error:.2e}\")\n# print(\"Valores grilla phi[50][25] \", gaussSeidel_vals[50][25])\n</code></pre></li> <li>LLamado a al funci\u00f3n del m\u00e9todo de Gauss-Seidel memoria compartida <pre><code>  int main(){\n  int iteraciones;\n  double error;\n\n  int num_procs;\n\n  std:: cout.precision(10); // configuramos la salida de decimales con una precision de 10 n\u00fameros\n  // iniciamos el temporizador\n  double time_1 = seconds();\n\n  std::tie(iteraciones, error) = gaussseidel(500, 1.0, -1.0, 1e-5, num_procs);\n  std::cout &lt;&lt; \"Convergencia alcanzada en \" &lt;&lt; iteraciones &lt;&lt; \" iteraciones con error \" &lt;&lt; error &lt;&lt; std::endl;\n\n\n  // Finalizamos el temporizador\n  double time_2 = seconds();\n\n  std::cout &lt;&lt; \"Numero de procesos: \" &lt;&lt; num_procs &lt;&lt; std::endl;\n  std::cout &lt;&lt; std::fixed &lt;&lt; std::setprecision(4);\n  std::cout &lt;&lt; \"Tiempo de ejecuci\u00f3n: \" &lt;&lt; time_2 - time_1 &lt;&lt; \" segundos\" &lt;&lt; std::endl;\n\n  return 0;\n}\n</code></pre></li> </ul> <p>Llamado a la funci\u00f3n de Gauss-Seidel memoria distribuida <pre><code>  int main(int argc, char**argv){\n  MPI_Init(&amp;argc,&amp;argv);\n  int rank; MPI_Comm_rank(MPI_COMM_WORLD,&amp;rank);\n\n  double t0 = seconds();\n  auto [its, delta] = gaussseidel_mpi(10, 100, 1.0, -1.0, 1e-5);\n  double t1 = seconds();\n\n  if(rank == 0){\n    std::cout&lt;&lt;\"Iteraciones: \"&lt;&lt;its&lt;&lt;\" error: \"&lt;&lt;delta&lt;&lt;\"\\n\";\n    std::cout&lt;&lt;\"Tiempo MPI: \"&lt;&lt;(t1-t0)&lt;&lt;\" s\\n\";\n  }\n\n  MPI_Finalize();\n  return 0;\n}\n</code></pre></p>"},{"location":"tutorials/#paso-5-ejecutamos-el-codigo","title":"Paso 5: Ejecutamos el c\u00f3digo","text":"<p>guardamos el archivo de jacobi.py, Sobre-relajaci\u00f3n de Jacobi, Gauss-Seidel, Gauss-Seidel memoria compartida, memoria distribuida y lo ejecutamos - primero a\u00f1adimos permisos de ejecuci\u00f3n: <pre><code>chmod +x jacobi.py\nchmod +x jacobi_modified.py\nchmod +x gauss_seidel.py\n</code></pre> - Segundo ejecutamos el c\u00f3digo <pre><code>./jacobi.py\n./jacobi_modified.py\n./gauss_seidel.py\n</code></pre> - para ejecutar los c\u00f3digo .cpp se hacen de la siguiente m\u00e1nera:   - para gaussseidel.cpp     <pre><code>g++ gaussseidel.cpp -o gaussseidel\ng++ -fopenmp gaussseidelmc.cpp -o gaussseidelmc\nmpicxx gaussseidelmd.cpp -o gaussseidelmd.x\n</code></pre>   - para ejecutar siguiendo el orden anterior     <pre><code>./gaussseidel\nexport OMP_NUM_THREADS=N &amp;&amp; ./gaussseidelmc\nmpirun -np X ./gaussseidelmd.x\n</code></pre>       - Donde N es el n\u00famero de hilos a utilizar.       - Donde X es el n\u00famero de procesos a utilizar.</p>"},{"location":"tutorials/#paso-6-graficar","title":"Paso 6: Graficar","text":"<p>Escribimos el c\u00f3digo a utilizar para realizar la gr\u00e1fica esperada Para los m\u00e9todos escritos en python la gr\u00e1fica es similar por ende solo presentamos un c\u00f3digo e imagen. <pre><code>plt.imshow(jacobi_vals, cmap='jet')  # Aplicar colormap expl\u00edcitamente\nplt.colorbar(label='Potencial el\u00e9ctrico')  # A\u00f1adir barra de color con etiqueta\nplt.title('Distribuci\u00f3n de potencial - M\u00e9todo de relajaci\u00f3n de Jacobi')\nplt.savefig('Jacobi.png', dpi=300)  # Guarda la imagen con buena resoluci\u00f3n\nplt.show()\n</code></pre></p> <p>Para el m\u00e9todo de Gauss-Seidel memoria compartida y distribuida se hizo la gr\u00e1fica de escalabilidad presentada en el apartado de: - Explicaci\u00f3n</p>"},{"location":"tutorials/#grafica","title":"Gr\u00e1fica:","text":""}]}