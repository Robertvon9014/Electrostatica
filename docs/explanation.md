# Explicaci贸n de los M茅todos Num茅ricos

## Problema f铆sico

Se resuelve la ecuaci贸n de Laplace bidimensional para el potencial el茅ctrico \(\phi(x,y)\):

\[
\frac{\partial^2 \phi}{\partial x^2} + \frac{\partial^2 \phi}{\partial y^2} = 0
\]

Esta ecuaci贸n nos permite describir el comportamiento de un potencial el茅ctrico sobre una regi贸n donde no existen cargas libres (es decir, en el 
vac铆o o en materiales diel茅ctricos).

El dominio de este problema se encuentra  en una placa cuadrada de 10 cm  10 cm, con dos barras internas que simulan las placas de un capacitor:
- Una barra se localiza cerca del borde izquierdo y se mantiene con potencial constante positivo $V_p$.
- Otra barra se encuentra cerca del borde derecho con potencial negativo $V_n$.

La longitud de ambas barras es de 6 cm, y est谩n separadas a la misma distancia que su longitud, lo cual nos permite visualizar una configuraci贸n sim茅trica con respecto al eje horizontal.

Condiciones del problema:
  - En las condiciones del problemas donde no se especifique el potencial se asume que la condici贸n de frontera tiene un valor inicial de cero, o 
    bien el potencial se actualiza iterativamente hasta converger.
  
---

## M茅todos implementados

### 1. M茅todo de relajaci贸n de Jacobi

Este m茅todo itera actualizando el potencial en cada punto de la malla usando el promedio de sus vecinos en la iteraci贸n anterior, manteniendo fijas las condiciones de frontera.

\[
\phi'(x, y) = \frac{1}{4}\left[\phi(x+a, y) + \phi(x-a, y) + \phi(x, y+a) + \phi(x, y-a)\right],
\]

La idea principal de este m茅todo es que se actualiza el valor del potencial el茅ctrico $\phi(x,y)$ en cada punto de la grilla como el promedio de los valores de sus vecinos adyacentes(arriba, abajo, izquierda, derecha) que se agarran de los datos iterativos anteriores, mientras mantenemos fijas las condiciones de frontera.

Esto se repite hasta que hayamos alcanzado una diferencia m谩xima entre dos iteraciones consecutivas, es lo que llamamos "el delta", y que este sea menor que una tolerancia escogida. Lo que nos indicar谩 que hemos alcanzado la convergencia.

- Es sencillo pero convergencia lenta.
- Requiere dos matrices para mantener valores antiguos y nuevos.

---

### 2. M茅todo de sobre-relajaci贸n de Jacobi (Jacobi modificado)

Se aplica un factor de sobre-relajaci贸n \(\omega\) para acelerar la convergencia, mezclando el valor nuevo calculado con el anterior:

\[
\phi'(x, y) = (1+\omega)\left[\frac{\phi(x+a, y) + \phi(x-a, y) + \phi(x, y+a) + \phi(x, y-a)}4\right] - \omega \phi (x,y).
\]

- Acelera la convergencia respecto al Jacobi est谩ndar.
- Requiere ajuste del par谩metro \(\omega\) para optimizar rendimiento.

Limitaciones: 
No siempre el m茅todo de Sobre-relajaci贸n de jacobi funcionar谩 ya que este m茅todo es muy inestable para grillas cuadradas, esto sucede debido a que 
el m茅todo no actualiza los valores al instante como lo hace Gauss-Seidel, es por ello que al intentar la sobre-relajaci贸n los valores del error se 
amplifican, esto debido a las condiciones de frontera internas, como lo son las barras con un voltaje de $\pm 1$, como estan internamente esto 
permite la generaci贸n de una regi贸n central en la cual los errores circulan libremente sin ser frenados por los bordes r铆gidos. Debido a que este 
m茅todo se vuelv num茅ricamente inestable incluso para valores $\omega < 1$, esto nos demuestra que la estabilidad del m茅todo no solo va a depender 
del factor de relajaci贸n $\omega$, sino tambi茅n de la geometr铆a del problema y las condiciones de frontera.

Una forma de poder utilizar el m茅todo de sobre-relajaci贸n de jacobi, para una placa cuadrada con barras internas con voltaje, es utilizar el m茅todo 
de sobre-relajaci贸n sucesiva (SOR) lo que nos permite esto es hacer iteraciones paralelas sin necesidad de usar valores ya actualizados.

\[
\phi'(x, y) = (1 - \omega) \cdot \phi(x, y) + \frac{\omega}{4} \cdot \left( \phi(x+1, y) + \phi(x-1, y) + \phi(x, y+1) + \phi(x, y-1) \right)
\]

---

### 3. M茅todo de Gauss-Seidel

En este m茅todo, la actualizaci贸n del potencial en cada punto usa los valores m谩s recientes disponibles (actualizados durante la misma iteraci贸n), 
mejorando la velocidad de convergencia frente a Jacobi. Esto facilita a la informaci贸n propagarse m谩s r谩pidamente a trav茅s de la grilla.

\[
\phi(x, y) \leftarrow \frac{\phi(x+a, y) + \phi(x-a, y) + \phi(x, y+a) + \phi(x, y-a)}{4}.
\]

- Solo se necesita una matriz.
- Mejor convergencia en menos iteraciones.
- Los valores reci茅n calculados se utilizan en el mismo ciclo.

aunque este m茅todo es m谩s r谩pido que Jacobi, la forma(orden) de actualizar los puntos puede influir en la estabilidad y el patr贸n de error.

---

### 4. M茅todo de Gauss-Seidel en C++

Implementaci贸n equivalente al m茅todo de Gauss-Seidel en Python, pero usando C++ con `std::vector` y `std::tuple`.

- Permite una posible extensi贸n para paralelizaci贸n.
- Mejora en eficiencia y manejo de memoria para casos grandes.

---

## Condiciones de frontera y configuraci贸n de la grilla

- La placa se discretiza en una malla de \((M+1) \times (M+1)\) puntos.
- Dos barras verticales se colocan a 2 cm de cada borde lateral, con longitudes de 6 cm, y potenciales fijos \(V_p\) y \(V_n\).
- El resto de bordes y posiciones iniciales son 0.

---

## Convergencia y criterio de parada

La iteraci贸n se detiene cuando la diferencia m谩xima absoluta entre iteraciones consecutivas es menor que una tolerancia dada.

---

## Comparaci贸n y resultados

- El m茅todo de Gauss-Seidel converge m谩s r谩pido que Jacobi.
- La sobre-relajaci贸n mejora a煤n m谩s la velocidad si se escoge un \(\omega\) adecuado (por ejemplo, 0.9). Adem谩s de ello la forma geom茅trica y las condiciones de frontera son las adecuadas.
- La implementaci贸n en C++ es m谩s eficiente y es base para paralelizaci贸n futura.

## Gr谩fica de escalabilidad
En esta secci贸n incluiremos una gr谩fica de escalabilidad tomando en cuenta 2 hilos(threads) y para 3 tama帽os de M distintos(M = 500, 1000, 1500).
![Gr谩fica de escalabilidad](SpeedUp.png)

## An谩lisis
| M    | Hilos | Speedup real | Speedup ideal |
| ---- | ----- | ------------ | ------------- |
| 500  | 1     | 1.00         | 1             |
| 500  | 2     | 1.68         | 2             |
| 1000 | 1     | 1.00         | 1             |
| 1000 | 2     | 1.55         | 2             |
| 1500 | 1     | 1.00         | 1             |
| 1500 | 2     | 1.54         | 2             |

- Speedup ideal es la aceleraci贸n m谩xima te贸rica, que aumenta linealmente con el n煤mero de hilos (por ejemplo, con 2 hilos, el speedup ideal es 2).
- Speedup real muestra los valores obtenidos al correr el c贸digo en la computadora.

Observaciones
1. Aceleraci贸n sublineal: <br>
    En todos los casos, el speedup real con 2 hilos est谩 por debajo del ideal (1.68, 1.55 y 1.54 en vez de 2). Esto es normal y esperado debido a:

      - Sobrecarga de gesti贸n de hilos.
      - Costos de sincronizaci贸n y comunicaci贸n entre threads.
      - Acceso a memoria compartida y posibles contenciones.

2. Mejor escalabilidad con problema peque帽o (M=500):<br>
    El speedup para $ = 500$ con 2 hilos (1.68) es mayor que para $ = 1000$ y $ = 1500$ (alrededor de 1.55). Esto puede ser por:

      - El trabajo extra por manejar datos mayores y la sobrecarga paralela que no escala igual.
      - O bien, diferencias en la carga de trabajo por iteraci贸n (aunque usualmente problemas m谩s grandes escalan mejor, puede depender de 
        implementaci贸n).

3. Escalabilidad limitada a 2 hilos:<br>
      Solo se tiene datos para 1 y 2 hilos. Con solo dos puntos es dif铆cil trazar conclusiones s贸lidas. Idealmente, pruebas con m谩s hilos ayudar铆an 
      a ver tendencias.
